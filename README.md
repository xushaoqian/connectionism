# connectionism
connectionism ann

// 我在思考一种模拟神经元联结学习的算法，不同于bp反向学习
// 在我看来人脑底层是神经网络，上层是贝叶斯分类联结
// 在大量随机神经元联结的情况下，隐藏着许多有用的神经元结构，相当于已经训练好的权重
// 我们只要想办法找到这些有用的结构，选择神经网络最后一层，找出有用的神经元，加强这些联结就可以了
// 本质上避免局部最少值问题，但需要海量的随机神经元基础
// 本质上提高迁移学习能力，只需要联结不同的反馈接触点

// 模拟大脑联结学习时，初始化随机权重【2，360，60】，最后的60个随机特征是所有随机特征集。
// 训练不同的任务时，根据比较正负样本得到的特征，筛选出有用的激活特征。
// 预测不同的任务时，根据需要选择60个特征中的一部分有用特征进行预测。
